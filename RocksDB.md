# RocksDB

### RocksDB 介绍

RocksDB 是一个高性能的嵌入式键值存储数据库，专为键值数据设计。它是 Facebook 基于 LevelDB 深度优化充分利用多核处理器，并提供高效的存储和检索功能的一个开源的嵌入式持久化键值存储引擎。

### 关键特性

RocksDB 设计的核心是高效性和可靠性，以下是其主要特点：

- **高性能读写**：支持高吞吐量和低延迟的操作，特别适合写密集型工作负载。通过 LSM-tree（Log-Structured Merge-Tree）架构，实现快速写入和背景 compaction（合并）来优化读取。
- **列族（Column Families）**：允许将数据逻辑分区成多个列族，每个列族可以有独立的配置，如压缩策略。这在实际应用中常用于分离频繁访问和不频繁访问的数据，提高效率。
- **可插拔架构**：RocksDB 的设计允许轻松替换其组件，而不影响整体架构，例如自定义压缩算法或缓存策略。这使得它高度灵活。
- **持久化和可靠性**：数据持久存储在磁盘上，支持 WAL（Write-Ahead Log）以确保数据一致性，即使在崩溃时也能恢复。
- **压缩和优化**：内置多种压缩算法（如 Snappy、Zlib），并支持多级存储（Level-based compaction），减少存储空间占用。
- **嵌入式设计**：作为库直接链接到应用程序中，无需额外进程，支持 C++、Java 等多种语言绑定。
- **其他功能**：包括事务支持、备份/恢复、迭代器遍历，以及对 SSD 和 HDD 的优化。

这些特性使 RocksDB 适用于需要快速、可靠键值存储的场景，尤其在大数据和实时系统中。

### RocksDB 架构

RocksDB 的高性能源于 LSM-Tree 架构的分层存储设计，通过内存与磁盘的协同工作，将随机写转化为顺序写，核心组件包括以下几部分：

| 组件                     | 作用           | 关键细节                                                     |
| ------------------------ | -------------- | ------------------------------------------------------------ |
| WAL（预写日志）          | 保障数据持久化 | 写入操作先追加到 WAL，防止 MemTable 数据丢失，崩溃后可通过重放 WAL 恢复数据，支持按大小或时间滚动切分 |
| MemTable                 | 接收实时写入   | 内存中的可变结构，默认采用跳表，保证数据有序性，支持高并发写入，写入速度极快 |
| Immutable MemTable       | 过渡性只读结构 | MemTable 写满后转为只读状态，不再接收新写入，等待后台线程异步刷盘，避免阻塞前台写入 |
| SST 文件（有序字符串表） | 磁盘持久化存储 | 不可变的有序键值文件，按 Level 分层（L0 至 L6 等），L0 文件键范围重叠，上层文件键范围逐步有序且不重叠，90% 数据最终存储在最底层 |
| Manifest                 | 记录元数据变更 | 记录 SST 文件的层级、键范围、创建 / 删除等信息，搭配 WAL 保障文件变更操作的安全性，是数据恢复的重要依据 |

#### 核心读写流程

其读写流程围绕分层存储设计，通过内存优先操作和分层查询策略，平衡读写性能：

- **写入流程**：写入操作先追加到 WAL，确保数据不丢失；接着写入 MemTable 完成快速响应；当 MemTable 达到预设大小（默认常为 128MB），转为 Immutable MemTable；后台线程将 Immutable MemTable 的数据顺序刷入磁盘的 L0 层，形成 SST 文件；当某层 SST 文件达到阈值，触发 Compaction 合并到下一层，同时清理过期或重复数据。

- **读取流程**：读取时优先查询 MemTable，未命中则查询 Immutable MemTable；若仍未找到，从 L0 层开始逐层遍历 SST 文件；为减少磁盘 I/O，会通过布隆过滤器快速判断键是否存在于某 SST 文件，同时借助 Block Cache 缓存热点数据块，默认块大小 64KB，采用 LRU 算法淘汰冷数据。

#### Compaction 核心合并机制

随着 SST 文件增多，会出现读放大和空间浪费问题，Compaction 作为后台异步操作，是解决该问题的关键，其核心细节如下：

- **触发条件**：L0 层文件数达到默认阈值 4 个时触发；非 L0 层文件总大小超过该层阈值（默认每层大小为上层 10 倍）时触发；当 L0 文件数超 20 个会降速写入，达 36 个则暂停写入，避免查询性能恶化。

- **主流合并策略**：一是**Leveled Compaction**（默认），合并时保证同层 SST 文件键范围无重叠，适合读多写少场景，查询效率稳定，但写放大略高；二是**Universal Compaction**，仅合并同层级时间相近的 SST 文件，写放大低，适合写密集场景，但读放大和空间放大较明显；三是**FIFO Compaction**，按文件创建时间淘汰旧数据，适合时序数据等场景。

- **合并流程**：挑选待合并层级中需处理的 SST 文件，匹配下一层中键范围重叠的 SST 文件；将这些文件加载到内存归并排序，清理过期、重复数据；生成新的 SST 文件写入目标层级，最后删除旧文件。

#### 高级特性

- **列族（ColumnFamily）**：类似 MySQL 的表，用于逻辑隔离数据。每个列族有独立的 MemTable、SST 文件和 Compaction 策略，可单独配置压缩算法等参数，所有列族共享同一个 WAL，适合多数据集隔离场景。

- **多维度优化能力**：支持 Snappy、LZ4、Zstd 等多种压缩算法，且每层 SST 可配置不同压缩方式，平衡空间占用与解压性能；支持批量操作和只读事务，批量写入可提升高并发写入效率，只读事务通过快照隔离保障数据一致性。

- **多核与存储适配**：原生支持多核处理器，后台 Compaction、刷盘等操作采用多线程并行执行，默认线程池大小为 CPU 核心数减一（CPU≤8 核时）；针对 SSD 的顺序写优势优化，通过 append-only 方式减少磁盘寻道开销。

#### 关键问题与调优方向

RocksDB 存在 LSM-Tree 架构固有的三大放大问题，需针对性调优：一是写放大，Compaction 会重复写入数据，可通过调整 Compaction 策略、增大 SST 文件大小减少合并频率；二是读放大，查询可能跨多层文件，可合理配置布隆过滤器和 Block Cache 大小，建议分配机器 45%-60% 内存给 Block Cache；三是空间放大，未合并的过期数据占用额外空间，可通过调整 Compaction 触发阈值加速无效数据清理.

#### 典型应用场景

凭借高性能和灵活性，RocksDB 成为众多系统的底层存储核心：作为 TiDB、CockroachDB 等分布式数据库的存储引擎；作为 Flink 状态后端、Kafka 偏移量管理的存储组件；用于时序数据存储、TB 级持久化缓存，以及对象存储的元数据存储等场景。

### InnoDB vs RocksDB：写路径（Write Path）架构流程图

#### InnoDB 写路径流程图（B+Tree 引擎）

```sql
┌───────────────────────────────────────────────┐
│               Client / SQL Layer              │
└───────────────────────────────────────────────┘
                      │
                      ▼
┌───────────────────────────────────────────────┐
│        Prepare SQL → Row Format → Index       │
└───────────────────────────────────────────────┘
                      │
                      ▼
   ┌──────────────────────────────────────────┐
   │         InnoDB Redo Log (WAL)            │
   │  · 顺序写入 redo log buffer               │
   │  · 刷盘到 redo log file                   │
   └──────────────────────────────────────────┘
                      │
                      ▼
   ┌──────────────────────────────────────────┐
   │   Buffer Pool（缓存页，含脏页 dirty）       │
   │  · 修改对应页（B+Tree page）               │
   │  · 页被标记为 “脏” dirty page              │
   └──────────────────────────────────────────┘
                      │
                      ▼
    后台线程（异步）
                      │
                      ▼
┌──────────────────────────────────────────────┐
│     Flush Dirty Pages（随机写磁盘页）           │
│   · LRU flush / flush list                   │
│   · Doublewrite buffer 防止页半写              │
└──────────────────────────────────────────────┘
                      │
                      ▼
┌──────────────────────────────────────────────┐
│        数据最终落盘（.ibd / tablespace）        │
└──────────────────────────────────────────────┘

```

#### InnoDB 写路径特点总结

- 写入顺序：redo log → buffer pool → 脏页刷盘
- 数据是“原地更新”，随时间产生碎片、页分裂
- 随机写较多
- 双写缓冲（Doublewrite）保护数据页一致性
- 延迟相对平稳，但空间效率不如 LSM

#### RocksDB 写路径流程图（LSM 引擎）

```sql
┌───────────────────────────────────────────────┐
│                Application（KV）               │
└───────────────────────────────────────────────┘
                       │
                       ▼
   ┌──────────────────────────────────────────┐
   │        WAL（Write Ahead Log）             │
   │   · 顺序写入 WAL（非常快）                  │
   └──────────────────────────────────────────┘
                       │
                       ▼
   ┌──────────────────────────────────────────┐
   │      MemTable（可写，基于 skiplist）       │
   │   · 内存结构                              │
   │   · 写入后立即可读                         │
   └──────────────────────────────────────────┘
                       │
                       ▼
   MemTable 满时变为 Immutable MemTable（只读）
                       │
                       ▼
         后台线程 Flush（异步，顺序写）
                       │
                       ▼
┌──────────────────────────────────────────────┐
│   Flush → L0 SSTable（不可变文件，sorted）      │
└──────────────────────────────────────────────┘
                       │
                       ▼
         Compaction（后台合并多个 SST）
                       │
                       ▼
┌──────────────────────────────────────────────┐
│               L1 / L2 / L3 … SST             │
│    · 合并旧版本、删除记录                       │
│    · 排序文件，减少读放大                       │
└──────────────────────────────────────────────┘

```

#### RocksDB 写路径特点总结

- 写入顺序：WAL → MemTable → flush → compaction
- 全程顺序写，非常适合 SSD
- 不原地更新：所有更新都产生新文件
- 磁盘数据由多层 SST 组成（L0～Ln）
- compaction 是核心，决定写放大、延迟波动